{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SYSTEM_WGETRC = c:/progra~1/wget/etc/wgetrc\n",
      "syswgetrc = C:\\Program Files (x86)\\GnuWin32/etc/wgetrc\n",
      "--2021-02-27 22:10:17--  http://d28rh4a8wq0iu5.cloudfront.net/ads1/code/bm_preproc.py\n",
      "Resolving d28rh4a8wq0iu5.cloudfront.net... 13.225.143.199, 13.225.143.44, 13.225.143.82, ...\n",
      "Connecting to d28rh4a8wq0iu5.cloudfront.net|13.225.143.199|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9400 (9.2K) [application/octet-stream]\n",
      "Saving to: `bm_preproc.py'\n",
      "\n",
      "     0K .........                                             100% 1.75M=0.005s\n",
      "\n",
      "2021-02-27 22:10:17 (1.75 MB/s) - `bm_preproc.py' saved [9400/9400]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://d28rh4a8wq0iu5.cloudfront.net/ads1/code/bm_preproc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SYSTEM_WGETRC = c:/progra~1/wget/etc/wgetrc\n",
      "syswgetrc = C:\\Program Files (x86)\\GnuWin32/etc/wgetrc\n",
      "--2021-02-27 22:10:36--  http://d28rh4a8wq0iu5.cloudfront.net/ads1/data/chr1.GRCh38.excerpt.fasta\n",
      "Resolving d28rh4a8wq0iu5.cloudfront.net... 13.225.143.199, 13.225.143.44, 13.225.143.82, ...\n",
      "Connecting to d28rh4a8wq0iu5.cloudfront.net|13.225.143.199|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 810105 (791K) [application/octet-stream]\n",
      "Saving to: `chr1.GRCh38.excerpt.fasta'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  6%  309K 2s\n",
      "    50K .......... .......... .......... .......... .......... 12% 1.04M 1s\n",
      "   100K .......... .......... .......... .......... .......... 18% 2.97M 1s\n",
      "   150K .......... .......... .......... .......... .......... 25%  629K 1s\n",
      "   200K .......... .......... .......... .......... .......... 31% 1.30M 1s\n",
      "   250K .......... .......... .......... .......... .......... 37% 1.67M 1s\n",
      "   300K .......... .......... .......... .......... .......... 44%  541K 1s\n",
      "   350K .......... .......... .......... .......... .......... 50% 3.35M 0s\n",
      "   400K .......... .......... .......... .......... .......... 56%  711K 0s\n",
      "   450K .......... .......... .......... .......... .......... 63% 1.13M 0s\n",
      "   500K .......... .......... .......... .......... .......... 69%  559K 0s\n",
      "   550K .......... .......... .......... .......... .......... 75% 55.5M 0s\n",
      "   600K .......... .......... .......... .......... .......... 82% 2.90M 0s\n",
      "   650K .......... .......... .......... .......... .......... 88% 1.54M 0s\n",
      "   700K .......... .......... .......... .......... .......... 94% 1.05M 0s\n",
      "   750K .......... .......... .......... .......... .         100% 98.5M=0.8s\n",
      "\n",
      "2021-02-27 22:10:37 (1017 KB/s) - `chr1.GRCh38.excerpt.fasta' saved [810105/810105]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://d28rh4a8wq0iu5.cloudfront.net/ads1/data/chr1.GRCh38.excerpt.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occurrences, num_alignments, num_character_comparisons: ([0, 19], 20, 35)\n"
     ]
    }
   ],
   "source": [
    "def readGenome(filename):\n",
    "    genome = \"\"\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            if not line[0] == \">\":\n",
    "                genome += line.rstrip()\n",
    "\n",
    "    return genome\n",
    "\n",
    "def reverseComplement(s):\n",
    "    complement = \"\"\n",
    "    complements = {\"A\": \"T\", \"C\": \"G\", \"G\": \"C\", \"T\": \"A\", \"N\": \"N\"}\n",
    "    for base in s:\n",
    "        # complement += complements[base] would yield just the complement\n",
    "        complement = complements[base] + complement\n",
    "    return complement\n",
    "\n",
    "def naive(p, t):\n",
    "    occurrences = []\n",
    "    for i in range(len(t) - len(p) + 1):\n",
    "        match = True\n",
    "        for j in range(len(p)):\n",
    "            if t[i+j] != p[j]:\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)\n",
    "    return occurrences\n",
    "\n",
    "def naive_with_counts(p, t):\n",
    "    occurrences = []\n",
    "    num_alignments = 0\n",
    "    num_character_comparisons = 0\n",
    "    for i in range(len(t) - len(p) + 1):\n",
    "        num_alignments += 1\n",
    "        match = True\n",
    "        for j in range(len(p)):\n",
    "            num_character_comparisons += 1\n",
    "            if t[i+j] != p[j]:\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)\n",
    "    return (occurrences, num_alignments, num_character_comparisons)\n",
    "\n",
    "# p = 'word'\n",
    "# t = 'there would have been a time for such a word'\n",
    "p = 'needle'\n",
    "t = 'needle need noodle needle'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "print(f\"occurrences, num_alignments, num_character_comparisons: {occurrences, num_alignments, num_character_comparisons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occurrences, num_alignments, num_character_comparisons: ([0, 19], 5, 18)\n"
     ]
    }
   ],
   "source": [
    "from bm_preproc import BoyerMoore\n",
    "\n",
    "def boyer_moore(p, p_bm, t):\n",
    "    \"\"\"p is pattern, p_bm is Boyer-Moore object, t is the text we want to search in\"\"\"\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        shift = 1\n",
    "        mismatched = False  # update as we go\n",
    "        for j in range(len(p) - 1, -1, -1):\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    \n",
    "    return occurrences\n",
    "\n",
    "def boyer_moore_with_counts(p, p_bm, t):\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    num_alignments = 0\n",
    "    num_character_comparisons = 0\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        num_alignments += 1\n",
    "        shift = 1\n",
    "        mismatched = False  # update as we go\n",
    "        for j in range(len(p) - 1, -1, -1):\n",
    "            num_character_comparisons += 1\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return (occurrences, num_alignments, num_character_comparisons)\n",
    "\n",
    "# p = 'word'\n",
    "# t = 'there would have been a time for such a word'\n",
    "# lowercase_alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "# p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "p = 'needle'\n",
    "t = 'needle need noodle needle'\n",
    "lowercase_alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, t)\n",
    "print(f\"occurrences, num_alignments, num_character_comparisons: {occurrences, num_alignments, num_character_comparisons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occurrences, num_alignments, num_character_comparisons: ([56922], 799954, 984143)\n"
     ]
    }
   ],
   "source": [
    "# questions 1 and 2\n",
    "def readGenome(filename):\n",
    "    genome = \"\"\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            if not line[0] == \">\":\n",
    "                genome += line.rstrip()\n",
    "\n",
    "    return genome\n",
    "\n",
    "p = \"GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG\"\n",
    "t = readGenome(\"chr1.GRCh38.excerpt.fasta\")\n",
    "p_bm = BoyerMoore(p)\n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "print(f\"occurrences, num_alignments, num_character_comparisons: {occurrences, num_alignments, num_character_comparisons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occurrences, num_alignments, num_character_comparisons: ([56922], 127974, 165191)\n"
     ]
    }
   ],
   "source": [
    "# question 3\n",
    "\n",
    "def readGenome(filename):\n",
    "    genome = \"\"\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            if not line[0] == \">\":\n",
    "                genome += line.rstrip()\n",
    "\n",
    "    return genome\n",
    "\n",
    "p = \"GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG\"\n",
    "t = readGenome(\"chr1.GRCh38.excerpt.fasta\")\n",
    "p_bm = BoyerMoore(p)\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, t)\n",
    "print(f\"occurrences, num_alignments, num_character_comparisons: {occurrences, num_alignments, num_character_comparisons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SYSTEM_WGETRC = c:/progra~1/wget/etc/wgetrc\n",
      "syswgetrc = C:\\Program Files (x86)\\GnuWin32/etc/wgetrc\n",
      "--2021-02-28 14:13:18--  https://d28rh4a8wq0iu5.cloudfront.net/ads1/code/kmer_index.py\n",
      "Resolving d28rh4a8wq0iu5.cloudfront.net... 13.226.211.214, 13.226.211.176, 13.226.211.37, ...\n",
      "Connecting to d28rh4a8wq0iu5.cloudfront.net|13.226.211.214|:443... connected.\n",
      "ERROR: cannot verify d28rh4a8wq0iu5.cloudfront.net's certificate, issued by `/C=US/O=DigiCert Inc/CN=DigiCert Global CA G2':\n",
      "  Unable to locally verify the issuer's authority.\n",
      "To connect to d28rh4a8wq0iu5.cloudfront.net insecurely, use `--no-check-certificate'.\n",
      "Unable to establish SSL connection.\n"
     ]
    }
   ],
   "source": [
    "# question 4\n",
    "\n",
    "# Implement the pigeonhole principle using Index to find exact matches for the partitions. \n",
    "# Assume P always has length 24, and that we are looking for approximate matches with up to 2 mismatches (substitutions).\n",
    "# We will use an 8-mer index.\n",
    "\n",
    "# Download the Python module for building a k-mer index. \n",
    "\n",
    "# https://d28rh4a8wq0iu5.cloudfront.net/ads1/code/kmer_index.py\n",
    "\n",
    "# Write a function that, given a length-24 pattern P and given an Index object built on 8-mers,\n",
    "# finds all approximate occurrences of P within T with up to 2 mismatches. Insertions and deletions are not allowed. \n",
    "# Don't consider any reverse complements.\n",
    "\n",
    "# How many times does the string GGCGCGGTGGCTCACGCCTGTAAT, which is derived from a human Alu sequence, \n",
    "# occur with up to 2 substitutions in the excerpt of human chromosome 1?  (Don't consider reverse complements here.)\n",
    "\n",
    "# Hint 1: Multiple index hits might direct you to the same match multiple times,\n",
    "#         but be careful not to count a match more than once.\n",
    "\n",
    "# Hint 2: You can check your work by comparing the output of your new function to that of the \n",
    "#         naive_2mm function implemented in the previous module.\n",
    "\n",
    "!wget https://d28rh4a8wq0iu5.cloudfront.net/ads1/code/kmer_index.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "# question 4 continued\n",
    "\n",
    "import bisect\n",
    "\n",
    "class Index(object):\n",
    "    \"\"\" Holds a substring index for a text T \"\"\"\n",
    "\n",
    "    def __init__(self, t, k):\n",
    "        \"\"\" Create index from all substrings of t of length k \"\"\"\n",
    "        self.k = k  # k-mer length (k)\n",
    "        self.index = []\n",
    "        for i in range(len(t) - k + 1):  # for each k-mer\n",
    "            self.index.append((t[i:i+k], i))  # add (k-mer, offset) pair\n",
    "        self.index.sort()  # alphabetize by k-mer\n",
    "\n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first k-mer of p \"\"\"\n",
    "        kmer = p[:self.k]  # query with first k-mer\n",
    "        i = bisect.bisect_left(self.index, (kmer, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != kmer:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits\n",
    "\n",
    "def queryIndex(p, t, index):\n",
    "    k = index.k\n",
    "    offsets = []\n",
    "    for i in index.query(p):\n",
    "        if p[k:] == t[i+k:i+len(p)]:  # verifying that p at that offset matches t entirely\n",
    "            offsets.append(i)\n",
    "    return offsets\n",
    "\n",
    "def approximate_matching(p, t, n):\n",
    "    \"\"\"Function takes pattern p and text t. It finds all indices at which p matches t with up to n mismatches.\"\"\"\n",
    "    segment_length = int(round(len(p) / (n + 1)))  # without int, we could get a float number\n",
    "    all_matches = set()\n",
    "    for i in range(n + 1):\n",
    "        start = i * segment_length\n",
    "        end = min((i + 1) * segment_length, len(p))\n",
    "        p_bm = BoyerMoore(p[start:end], alphabet=\"ACGT\")\n",
    "        matches = boyer_moore(p[start:end], p_bm, t)\n",
    "        \n",
    "        for m in matches:\n",
    "            if m < start or m - start + len(p) > len(t):\n",
    "                continue  # skip the rest of this loop\n",
    "\n",
    "            mismatches = 0\n",
    "            for j in range(0, start):  # loop through the left side of the partition\n",
    "                if p[j] != t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            for j in range(end, len(p)):  # loop through the right side of the partition\n",
    "                if p[j] != t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "\n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m - start)\n",
    "    \n",
    "    return list(all_matches)\n",
    "\n",
    "p = \"GGCGCGGTGGCTCACGCCTGTAAT\"\n",
    "t = readGenome(\"chr1.GRCh38.excerpt.fasta\")\n",
    "n = 2\n",
    "occurrences = approximate_matching(p, t, n)\n",
    "print(len(occurrences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queryIndex: len(index.query(p)) = 13\n",
      "offsets = [56922, 262042, 364263, 657496, 717706]\n",
      "len(all_matches) = 19\n"
     ]
    }
   ],
   "source": [
    "# question 5\n",
    "\n",
    "# Using the instructions given in Question 4, how many total index hits are there when searching for occurrences of \n",
    "# GGCGCGGTGGCTCACGCCTGTAAT with up to 2 substitutions in the excerpt of human chromosome 1?\n",
    "# (Don't consider reverse complements.)\n",
    "\n",
    "# Hint: You should be able to use the boyer_moore function (or the slower naive function) to double-check your answer.\n",
    "\n",
    "import bisect\n",
    "\n",
    "class Index(object):\n",
    "    \"\"\" Holds a substring index for a text T \"\"\"\n",
    "\n",
    "    def __init__(self, t, k):\n",
    "        \"\"\" Create index from all substrings of t of length k \"\"\"\n",
    "        self.k = k  # k-mer length (k)\n",
    "        self.index = []\n",
    "        for i in range(len(t) - k + 1):  # for each k-mer\n",
    "            self.index.append((t[i:i+k], i))  # add (k-mer, offset) pair\n",
    "        self.index.sort()  # alphabetize by k-mer\n",
    "\n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first k-mer of p \"\"\"\n",
    "        kmer = p[:self.k]  # query with first k-mer\n",
    "        i = bisect.bisect_left(self.index, (kmer, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != kmer:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits\n",
    "\n",
    "def queryIndex(p, t, index):\n",
    "    k = index.k\n",
    "    offsets = []\n",
    "    for i in index.query(p):\n",
    "        if p[k:] == t[i+k:i+len(p)]:  # verifying that p at that offset matches t entirely\n",
    "            offsets.append(i)\n",
    "    print(f\"queryIndex: len(index.query(p)) = {len(index.query(p))}\")\n",
    "    return offsets\n",
    "\n",
    "def approximate_matching(p, t, n):\n",
    "    \"\"\"Function takes pattern p and text t. It finds all indices at which p matches t with up to n mismatches.\"\"\"\n",
    "    segment_length = int(round(len(p) / (n + 1)))  # without int, we could get a float number\n",
    "    all_matches = set()\n",
    "    for i in range(n + 1):\n",
    "        start = i * segment_length\n",
    "        end = min((i + 1) * segment_length, len(p))\n",
    "        p_bm = BoyerMoore(p[start:end], alphabet=\"ACGT\")\n",
    "        matches = boyer_moore(p[start:end], p_bm, t)\n",
    "        \n",
    "        for m in matches:\n",
    "            if m < start or m - start + len(p) > len(t):\n",
    "                continue  # skip the rest of this loop\n",
    "\n",
    "            mismatches = 0\n",
    "            for j in range(0, start):  # loop through the left side of the partition\n",
    "                if p[j] != t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            for j in range(end, len(p)):  # loop through the right side of the partition\n",
    "                if p[j] != t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "\n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m - start)\n",
    "    \n",
    "    return list(all_matches)\n",
    "\n",
    "p = \"GGCGCGGTGGCTCACGCCTGTAAT\"\n",
    "t = readGenome(\"chr1.GRCh38.excerpt.fasta\")\n",
    "k = 8\n",
    "n = 2\n",
    "index = Index(t, k)\n",
    "offsets = queryIndex(p, t, index)\n",
    "print(f\"offsets = {offsets}\")\n",
    "all_matches = approximate_matching(p, t, n)\n",
    "print(f\"len(all_matches) = {len(all_matches)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first element: [56922, 57056, 83720, 84641, 147558, 160729, 191452, 262042, 364263, 657496, 681737, 717706, 725061]\n",
      "first element: 13\n",
      "second element: [56923, 57057, 83721, 84642, 147559, 160730, 191453, 262043, 364264, 429300, 657497, 681738, 717707, 725062]\n",
      "second element: 14\n",
      "third element: [56924, 57058, 84643, 147560, 160731, 191454, 262044, 359294, 364265, 429301, 657498, 681739, 717708, 725063]\n",
      "third element: 14\n"
     ]
    }
   ],
   "source": [
    "import bisect\n",
    "\n",
    "class Index(object):\n",
    "    \"\"\" Holds a substring index for a text T \"\"\"\n",
    "\n",
    "    def __init__(self, t, k):\n",
    "        \"\"\" Create index from all substrings of t of length k \"\"\"\n",
    "        self.k = k  # k-mer length (k)\n",
    "        self.index = []\n",
    "        for i in range(len(t) - k + 1):  # for each k-mer\n",
    "            self.index.append((t[i:i+k], i))  # add (k-mer, offset) pair\n",
    "        self.index.sort()  # alphabetize by k-mer\n",
    "\n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first k-mer of p \"\"\"\n",
    "        kmer = p[:self.k]  # query with first k-mer\n",
    "        i = bisect.bisect_left(self.index, (kmer, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != kmer:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits\n",
    "    \n",
    "p = \"GGCGCGGTGGCTCACGCCTGTAAT\"\n",
    "t = readGenome(\"chr1.GRCh38.excerpt.fasta\")\n",
    "k = 8\n",
    "\n",
    "index = Index(t, k)\n",
    "\n",
    "print(f\"first element: {index.query(p[0:])}\")\n",
    "print(f\"first element: {len(index.query(p[0:]))}\")\n",
    "print(f\"second element: {index.query(p[1:])}\")\n",
    "print(f\"second element: {len(index.query(p[1:]))}\")\n",
    "print(f\"third element: {index.query(p[2:])}\")\n",
    "print(f\"third element: {len(index.query(p[2:]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boyer_moore: len(occurrences) = 5\n",
      "naive_2mismatches: len(total_hits) = 19\n",
      "boyer_moore_2mismatches: len(hits) = 0\n",
      "boyer_moore_2mismatches n = 0: len(hits) = 5\n"
     ]
    }
   ],
   "source": [
    "from bm_preproc import BoyerMoore\n",
    "\n",
    "def boyer_moore_with_counts(p, p_bm, t):\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    num_alignments = 0\n",
    "    num_character_comparisons = 0\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        num_alignments += 1\n",
    "        shift = 1\n",
    "        mismatched = False  # update as we go\n",
    "        for j in range(len(p) - 1, -1, -1):\n",
    "            num_character_comparisons += 1\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return (occurrences, num_alignments, num_character_comparisons)\n",
    "\n",
    "def boyer_moore(p, p_bm, t):\n",
    "    \"\"\"p is pattern, p_bm is Boyer-Moore object, t is the text we want to search in\"\"\"\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        shift = 1\n",
    "        mismatched = False  # update as we go\n",
    "        for j in range(len(p) - 1, -1, -1):\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    \n",
    "    return occurrences\n",
    "\n",
    "def boyer_moore_2mismatches(p, p_bm, t, n):\n",
    "    \"\"\"p is pattern, p_bm is Boyer-Moore object, t is the text we want to search in, n is number of mismatches\"\"\"\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        shift = 1\n",
    "        n_mismatches = 0\n",
    "        for j in range(len(p) - 1, -1, -1):\n",
    "            if p[j] != t[i+j]:\n",
    "                n_mismatches += 1\n",
    "                if n_mismatches > n:\n",
    "                    skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                    skip_gs = p_bm.good_suffix_rule(j)\n",
    "                    shift = max(shift, skip_bc, skip_gs)\n",
    "                    # print(f\"boyer_moore_2mismatches: shift = {shift}\")\n",
    "                    break\n",
    "            pass\n",
    "        if n_mismatches <= n:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    \n",
    "    return occurrences\n",
    "\n",
    "def naive_2mismatches(p, t):\n",
    "    occurrences = []\n",
    "    for i in range(len(t) - len(p) + 1):\n",
    "        match = True\n",
    "        n_mismatches = 0\n",
    "        for j in range(len(p)):\n",
    "            if t[i+j] != p[j]:\n",
    "                # match = False\n",
    "                n_mismatches += 1\n",
    "                if n_mismatches > 2:\n",
    "                    match = False\n",
    "                    break\n",
    "        if match:\n",
    "            occurrences.append(i)\n",
    "    return occurrences\n",
    "\n",
    "p = \"GGCGCGGTGGCTCACGCCTGTAAT\"\n",
    "t = readGenome(\"chr1.GRCh38.excerpt.fasta\")\n",
    "p_bm = BoyerMoore(p)\n",
    "n = 2\n",
    "occurrences = boyer_moore(p, p_bm, t)\n",
    "print(f\"boyer_moore: len(occurrences) = {len(occurrences)}\")\n",
    "\n",
    "total_hits = naive_2mismatches(p, t)\n",
    "print(f\"naive_2mismatches: len(total_hits) = {len(total_hits)}\")\n",
    "\n",
    "hits = boyer_moore_2mismatches(p, p_bm, t, n)\n",
    "print(f\"boyer_moore_2mismatches: len(hits) = {len(hits)}\")\n",
    "\n",
    "hits = boyer_moore_2mismatches(p, p_bm, t, 0)\n",
    "print(f\"boyer_moore_2mismatches n = 0: len(hits) = {len(hits)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AAA', 0), ('TTT', 1)]\n",
      "[]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# question 6\n",
    "\n",
    "# Let's examine whether there is a benefit to using an index built using subsequences of T rather than substrings, \n",
    "# as we discussed in the \"Variations on k-mer indexes\" video.  We'll consider subsequences involving every N characters.\n",
    "# For example, if we split ATATAT into two substring partitions, we would get partitions ATA (the first half) \n",
    "# and TAT (second half).  But if we split ATATAT into two  subsequences  by taking every other character, we would get AAA\n",
    "# (first, third and fifth characters) and TTT (second, fourth and sixth).\n",
    "\n",
    "# Another way to visualize this is using numbers to show how each character of P is allocated to a partition.\n",
    "# Splitting a length-6 pattern into two substrings could be represented as 111222, and \n",
    "# splitting into two subsequences of every other character could be represented as 121212\n",
    "\n",
    "# The following class SubseqIndex is a more general implementation of Index that additionally handles subsequences.\n",
    "# It only considers subsequences that take every Nth character.\n",
    "\n",
    "# Write a function that, given a length-24 pattern P and given a SubseqIndex object built with k = 8 and ival = 3,\n",
    "# finds all approximate occurrences of P within T with up to 2 mismatches.\n",
    "\n",
    "# When using this function, how many total index hits are there when searching for GGCGCGGTGGCTCACGCCTGTAAT with up to\n",
    "# 2 substitutions in the excerpt of human chromosome 1?  (Again, don't consider reverse complements.)\n",
    "\n",
    "import bisect\n",
    "   \n",
    "class SubseqIndex(object):\n",
    "    \"\"\" Holds a subsequence index for a text T \"\"\"\n",
    "    \n",
    "    def __init__(self, t, k, ival):\n",
    "        \"\"\" Create index from all subsequences consisting of k characters\n",
    "            spaced ival positions apart.  E.g., SubseqIndex(\"ATAT\", 2, 2)\n",
    "            extracts (\"AA\", 0) and (\"TT\", 1). \"\"\"\n",
    "        self.k = k  # num characters per subsequence extracted\n",
    "        self.ival = ival  # space between them; 1=adjacent, 2=every other, etc\n",
    "        self.index = []\n",
    "        self.span = 1 + ival * (k - 1)\n",
    "        for i in range(len(t) - self.span + 1):  # for each subseq\n",
    "            self.index.append((t[i:i+self.span:ival], i))  # add (subseq, offset)\n",
    "        self.index.sort()  # alphabetize by subseq\n",
    "    \n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first subseq of p \"\"\"\n",
    "        subseq = p[:self.span:self.ival]  # query with first subseq\n",
    "        i = bisect.bisect_left(self.index, (subseq, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != subseq:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits\n",
    "\n",
    "ind = SubseqIndex('ATATAT', 3, 2)\n",
    "print(ind.index)\n",
    "p = 'TTATAT'\n",
    "print(ind.query(p[0:]))\n",
    "print(ind.query(p[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[56922, 262042, 273669, 364263, 465647, 657496, 717706]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question 6 continued\n",
    "# Write a function that, given a length-24 pattern P and given a SubseqIndex object built with k = 8 and ival = 3,\n",
    "# finds all approximate occurrences of P within T with up to 2 mismatches.\n",
    "\n",
    "# When using this function, how many total index hits are there when searching for GGCGCGGTGGCTCACGCCTGTAAT with up to\n",
    "# 2 substitutions in the excerpt of human chromosome 1?  (Again, don't consider reverse complements.)\n",
    "\n",
    "import bisect\n",
    "   \n",
    "class SubseqIndex(object):\n",
    "    \"\"\" Holds a subsequence index for a text T \"\"\"\n",
    "    \n",
    "    def __init__(self, t, k, ival):\n",
    "        \"\"\" Create index from all subsequences consisting of k characters\n",
    "            spaced ival positions apart.  E.g., SubseqIndex(\"ATAT\", 2, 2)\n",
    "            extracts (\"AA\", 0) and (\"TT\", 1). \"\"\"\n",
    "        self.k = k  # num characters per subsequence extracted\n",
    "        self.ival = ival  # space between them; 1=adjacent, 2=every other, etc\n",
    "        self.index = []\n",
    "        self.span = 1 + ival * (k - 1)\n",
    "        for i in range(len(t) - self.span + 1):  # for each subseq\n",
    "            self.index.append((t[i:i+self.span:ival], i))  # add (subseq, offset)\n",
    "        self.index.sort()  # alphabetize by subseq\n",
    "    \n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first subseq of p \"\"\"\n",
    "        subseq = p[:self.span:self.ival]  # query with first subseq\n",
    "        i = bisect.bisect_left(self.index, (subseq, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != subseq:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits\n",
    "    \n",
    "def queryIndex(p, t, index):\n",
    "    k = index.k\n",
    "    offsets = []\n",
    "    for i in index.query(p):\n",
    "        if p[k:] == t[i+k:i+len(p)]:  # verifying that p at that offset matches t entirely\n",
    "            offsets.append(i)\n",
    "    print(len(index.query(p)))\n",
    "    return offsets\n",
    "\n",
    "def approximate_matching(p, t, n):\n",
    "    \"\"\"Function takes pattern p and text t. It finds all indices at which p matches t with up to n mismatches.\"\"\"\n",
    "    segment_length = int(round(len(p) / (n + 1)))  # without int, we could get a float number\n",
    "    all_matches = set()\n",
    "    for i in range(n + 1):\n",
    "        start = i * segment_length\n",
    "        end = min((i + 1) * segment_length, len(p))\n",
    "        p_bm = BoyerMoore(p[start:end], alphabet=\"ACGT\")\n",
    "        matches = boyer_moore(p[start:end], p_bm, t)\n",
    "        \n",
    "        for m in matches:\n",
    "            if m < start or m - start + len(p) > len(t):\n",
    "                continue  # skip the rest of this loop\n",
    "\n",
    "            mismatches = 0\n",
    "            for j in range(0, start):  # loop through the left side of the partition\n",
    "                if p[j] != t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            for j in range(end, len(p)):  # loop through the right side of the partition\n",
    "                if p[j] != t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "\n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m - start)\n",
    "    \n",
    "    return list(all_matches), len(list(all_matches))\n",
    "\n",
    "# p = \"GGCGCGGTGGCTCACGCCTGTAAT\"\n",
    "# t = readGenome(\"chr1.GRCh38.excerpt.fasta\")\n",
    "# k = 8\n",
    "# ival = 3\n",
    "# n = 2\n",
    "\n",
    "p = \"GGCGCGGTGGCTCACGCCTGTAAT\"\n",
    "t = readGenome(\"chr1.GRCh38.excerpt.fasta\")\n",
    "k = 8\n",
    "index = SubseqIndex(t, k, ival)\n",
    "queryIndex(p, t, index)\n",
    "\n",
    "# t = 'to-morrow and to-morrow and to-morrow creeps in this petty pace'\n",
    "# p = 'to-morrow and to-morrow '\n",
    "# subseq_ind = SubseqIndex(t, 8, 3)\n",
    "# occurrences, num_index_hits = SubseqIndex.query(p, t, subseq_ind)\n",
    "# print(f\"occurrences, num_index_hits: {occurrences, num_index_hits}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
